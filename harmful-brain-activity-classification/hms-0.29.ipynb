{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c4383a",
   "metadata": {
    "papermill": {
     "duration": 0.029539,
     "end_time": "2024-03-29T14:18:07.913219",
     "exception": false,
     "start_time": "2024-03-29T14:18:07.883680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# >> Model 1 <<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0deb18b2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:07.974657Z",
     "iopub.status.busy": "2024-03-29T14:18:07.973405Z",
     "iopub.status.idle": "2024-03-29T14:18:14.531397Z",
     "shell.execute_reply": "2024-03-29T14:18:14.529839Z"
    },
    "papermill": {
     "duration": 6.590395,
     "end_time": "2024-03-29T14:18:14.533919",
     "exception": false,
     "start_time": "2024-03-29T14:18:07.943524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 22.04.3 LTS\r\n",
      "BUILD_DATE=20240109-221321, CONTAINER_NAME=tf2-gpu/2-13+gpu\n",
      "PyTorch Version:2.0.0, CUDA is available:True, Version CUDA:11.8\n",
      "Device Capability:(6, 0), ['sm_37', 'sm_60', 'sm_70', 'sm_75', 'compute_70', 'compute_75']\n",
      "CuDNN Enabled:True, Version:8900\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.append(\"/kaggle/input/kaggle-kl-div\")\n",
    "from kaggle_kl_div import score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "!cat /etc/os-release | grep -oP \"PRETTY_NAME=\\\"\\K([^\\\"]*)\"\n",
    "print(f\"BUILD_DATE={os.environ['BUILD_DATE']}, CONTAINER_NAME={os.environ['CONTAINER_NAME']}\")\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"PyTorch Version:{torch.__version__}, CUDA is available:{torch.cuda.is_available()}, Version CUDA:{torch.version.cuda}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Device Capability:{torch.cuda.get_device_capability()}, {torch.cuda.get_arch_list()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"CuDNN Enabled:{torch.backends.cudnn.enabled}, Version:{torch.backends.cudnn.version()}\"\n",
    "    )\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf1d4e",
   "metadata": {
    "papermill": {
     "duration": 0.028756,
     "end_time": "2024-03-29T14:18:14.591417",
     "exception": false,
     "start_time": "2024-03-29T14:18:14.562661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ad6fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:14.656022Z",
     "iopub.status.busy": "2024-03-29T14:18:14.655210Z",
     "iopub.status.idle": "2024-03-29T14:18:14.668156Z",
     "shell.execute_reply": "2024-03-29T14:18:14.667096Z"
    },
    "papermill": {
     "duration": 0.045905,
     "end_time": "2024-03-29T14:18:14.670420",
     "exception": false,
     "start_time": "2024-03-29T14:18:14.624515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    VERSION = 88\n",
    "\n",
    "    model_name = \"resnet1d_gru\"\n",
    "\n",
    "    seed = 2024\n",
    "    batch_size = 32\n",
    "    num_workers = 0\n",
    "\n",
    "    fixed_kernel_size = 5\n",
    "    # kernels = [3, 5, 7, 9]\n",
    "    # linear_layer_features = 424\n",
    "    kernels = [3, 5, 7, 9, 11]\n",
    "    #linear_layer_features = 448  # Full Signal = 10_000\n",
    "    #linear_layer_features = 352  # Half Signal = 5_000\n",
    "    linear_layer_features = 304   # 1/5  Signal = 2_000\n",
    "\n",
    "    seq_length = 50  # Second's\n",
    "    sampling_rate = 200  # Hz\n",
    "    nsamples = seq_length * sampling_rate  # Число семплов\n",
    "    out_samples = nsamples // 5\n",
    "\n",
    "    # bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n",
    "    # rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n",
    "    freq_channels = []  # [(8.0, 12.0)]; [(0.5, 4.5)]\n",
    "    filter_order = 2\n",
    "    random_close_zone = 0.0  # 0.2\n",
    "        \n",
    "    target_cols = [\n",
    "        \"seizure_vote\",\n",
    "        \"lpd_vote\",\n",
    "        \"gpd_vote\",\n",
    "        \"lrda_vote\",\n",
    "        \"grda_vote\",\n",
    "        \"other_vote\",\n",
    "    ]\n",
    "\n",
    "    # target_preds = [x + \"_pred\" for x in target_cols]\n",
    "    # label_to_num = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n",
    "    # num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "\n",
    "    map_features = [\n",
    "        (\"Fp1\", \"T3\"),\n",
    "        (\"T3\", \"O1\"),\n",
    "        (\"Fp1\", \"C3\"),\n",
    "        (\"C3\", \"O1\"),\n",
    "        (\"Fp2\", \"C4\"),\n",
    "        (\"C4\", \"O2\"),\n",
    "        (\"Fp2\", \"T4\"),\n",
    "        (\"T4\", \"O2\"),\n",
    "        #('Fz', 'Cz'), ('Cz', 'Pz'),        \n",
    "    ]\n",
    "\n",
    "    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz']\n",
    "        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']                    \n",
    "    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n",
    "    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n",
    "\n",
    "    # eeg_features = [row for row in feature_to_index]\n",
    "    # eeg_feat_size = len(eeg_features)\n",
    "    \n",
    "    n_map_features = len(map_features)\n",
    "    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n",
    "    target_size = len(target_cols)\n",
    "    \n",
    "    PATH = \"/kaggle/input/hms-harmful-brain-activity-classification/\"\n",
    "    test_eeg = \"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/\"\n",
    "    test_csv = \"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b147a85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:14.730679Z",
     "iopub.status.busy": "2024-03-29T14:18:14.729579Z",
     "iopub.status.idle": "2024-03-29T14:18:14.735985Z",
     "shell.execute_reply": "2024-03-29T14:18:14.734965Z"
    },
    "papermill": {
     "duration": 0.038403,
     "end_time": "2024-03-29T14:18:14.738198",
     "exception": false,
     "start_time": "2024-03-29T14:18:14.699795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "koef_1 = 1.0\n",
    "model_weights = [\n",
    "    {\n",
    "        'bandpass_filter':{'low':0.5, 'high':20, 'order':2}, \n",
    "        'file_data': \n",
    "        [\n",
    "            #{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v82/pop_1_weight_oof/*_best.pth\"},\n",
    "            {'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v82/pop_2_weight_oof/*_best.pth\"},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# 2-Stage\n",
    "#{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v82/pop_2_weight_oof/*_best.pth\"},  # 0.36 +++\n",
    "#{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v84/pop_2_weight_oof/*_best.pth\"},  # 0.37\n",
    "#{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v96-full/pop_2_weight_oof/*_full.pth\"},  # 0.36 +\n",
    "#{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v98/pop_2_weight_oof/*_full.pth\"},  # 0.36 ++\n",
    "            \n",
    "# 3-Stage\n",
    "#{'koef':koef_1, 'file_mask':\"/kaggle/input/hms-resnet1d-gru-weights-v90/pop_3_weight_oof/*_best.pth\"},  # 0.36 ++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c230b1",
   "metadata": {
    "papermill": {
     "duration": 0.028254,
     "end_time": "2024-03-29T14:18:14.795575",
     "exception": false,
     "start_time": "2024-03-29T14:18:14.767321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca0739f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:14.854557Z",
     "iopub.status.busy": "2024-03-29T14:18:14.854153Z",
     "iopub.status.idle": "2024-03-29T14:18:14.881034Z",
     "shell.execute_reply": "2024-03-29T14:18:14.880060Z"
    },
    "papermill": {
     "duration": 0.05927,
     "end_time": "2024-03-29T14:18:14.883221",
     "exception": false,
     "start_time": "2024-03-29T14:18:14.823951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=\"./test.log\"):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x  # quantized\n",
    "\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(\n",
    "    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n",
    "):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    # Частота дискретизации и желаемые частоты среза (в Гц).\n",
    "    # Отфильтруйте шумный сигнал\n",
    "    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n",
    "    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n",
    "    y = y[0:-1:4]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678878c9",
   "metadata": {
    "papermill": {
     "duration": 0.02732,
     "end_time": "2024-03-29T14:18:14.984009",
     "exception": false,
     "start_time": "2024-03-29T14:18:14.956689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parquet to EEG Signals Numpy Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381c8274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:15.043216Z",
     "iopub.status.busy": "2024-03-29T14:18:15.042657Z",
     "iopub.status.idle": "2024-03-29T14:18:15.055715Z",
     "shell.execute_reply": "2024-03-29T14:18:15.054597Z"
    },
    "papermill": {
     "duration": 0.045824,
     "end_time": "2024-03-29T14:18:15.058016",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.012192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eeg_from_parquet(\n",
    "    parquet_path: str, display: bool = False, seq_length=CFG.seq_length\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Эта функция читает файл паркета и извлекает средние 50 секунд показаний. Затем он заполняет значения NaN\n",
    "    со средним значением (игнорируя NaN).\n",
    "        :param parquet_path: путь к файлу паркета.\n",
    "        :param display: отображать графики ЭЭГ или нет.\n",
    "        :return data: np.array формы (time_steps, eeg_features) -> (10_000, 8)\n",
    "    \"\"\"\n",
    "\n",
    "    # Вырезаем среднюю 50 секундную часть\n",
    "    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n",
    "    rows = len(eeg)\n",
    "\n",
    "    # начало смещения данных, чтобы забрать середину\n",
    "    offset = (rows - CFG.nsamples) // 2\n",
    "\n",
    "    # средние 50 секунд, имеет одинаковое количество показаний слева и справа\n",
    "    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        offset = 0\n",
    "\n",
    "    # Конвертировать в numpy\n",
    "\n",
    "    # создать заполнитель той же формы с нулями\n",
    "    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n",
    "\n",
    "    for index, feature in enumerate(CFG.eeg_features):\n",
    "        x = eeg[feature].values.astype(\"float32\")  # конвертировать в float32\n",
    "\n",
    "        # Вычисляет среднее арифметическое вдоль указанной оси, игнорируя NaN.\n",
    "        mean = np.nanmean(x)\n",
    "        nan_percentage = np.isnan(x).mean()  # percentage of NaN values in feature\n",
    "\n",
    "        # Заполнение значения Nan\n",
    "        # Поэлементная проверка на NaN и возврат результата в виде логического массива.\n",
    "        if nan_percentage < 1:  # если некоторые значения равны Nan, но не все\n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else:  # если все значения — Nan\n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "\n",
    "        if display:\n",
    "            if index != 0:\n",
    "                offset += x.max()\n",
    "            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n",
    "            offset -= x.min()\n",
    "\n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"EEG {name}\", size=16)\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e0d6c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:15.118813Z",
     "iopub.status.busy": "2024-03-29T14:18:15.118434Z",
     "iopub.status.idle": "2024-03-29T14:18:15.144608Z",
     "shell.execute_reply": "2024-03-29T14:18:15.143652Z"
    },
    "papermill": {
     "duration": 0.059287,
     "end_time": "2024-03-29T14:18:15.146914",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.087627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        eegs: Dict[int, np.ndarray],\n",
    "        mode: str = \"train\",\n",
    "        downsample: int = None,\n",
    "        bandpass_filter: Dict[str, Union[int, float]] = None,\n",
    "        rand_filter: Dict[str, Union[int, float]] = None,\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = downsample\n",
    "        self.bandpass_filter = bandpass_filter\n",
    "        self.rand_filter = rand_filter\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        # Обозначает количество пакетов за эпоху\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        # Сгенерировать один пакет данных\n",
    "        X, y_prob = self.__data_generation(index)\n",
    "        if self.downsample is not None:\n",
    "            X = X[:: self.downsample, :]\n",
    "        output = {\n",
    "            \"eeg\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        # Генерирует данные, содержащие образцы размера партии\n",
    "        X = np.zeros(\n",
    "            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n",
    "        )  # Size=(10000, 14)\n",
    "\n",
    "        row = self.df.iloc[index]  # Строка Pandas\n",
    "        data = self.eegs[row.eeg_id]  # Size=(10000, 8)\n",
    "        if CFG.nsamples != CFG.out_samples:\n",
    "            if self.mode != \"train\":\n",
    "                offset = (CFG.nsamples - CFG.out_samples) // 2\n",
    "            else:\n",
    "                #offset = random.randint(0, CFG.nsamples - CFG.out_samples)                \n",
    "                offset = ((CFG.nsamples - CFG.out_samples) * random.randint(0, 1000)) // 1000\n",
    "            data = data[offset:offset+CFG.out_samples,:]\n",
    "\n",
    "        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n",
    "            if self.mode == \"train\" and CFG.random_close_zone > 0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:\n",
    "                continue\n",
    "                \n",
    "            diff_feat = (\n",
    "                data[:, CFG.feature_to_index[feat_a]]\n",
    "                - data[:, CFG.feature_to_index[feat_b]]\n",
    "            )  # Size=(10000,)\n",
    "\n",
    "            if not self.bandpass_filter is None:\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "                    \n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, i] = diff_feat\n",
    "\n",
    "        n = CFG.n_map_features\n",
    "        if len(CFG.freq_channels) > 0:\n",
    "            for i in range(CFG.n_map_features):\n",
    "                diff_feat = X[:, i]\n",
    "                for j, (lowcut, highcut) in enumerate(CFG.freq_channels):\n",
    "                    band_feat = butter_bandpass_filter(\n",
    "                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n",
    "                    )\n",
    "                    X[:, n] = band_feat\n",
    "                    n += 1\n",
    "\n",
    "        for spml_feat in CFG.simple_features:\n",
    "            feat_val = data[:, CFG.feature_to_index[spml_feat]]\n",
    "            \n",
    "            if not self.bandpass_filter is None:\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, n] = feat_val\n",
    "            n += 1\n",
    "            \n",
    "        # Обрезать края превышающие значения [-1024, 1024]\n",
    "        X = np.clip(X, -1024, 1024)\n",
    "\n",
    "        # Замените NaN нулем и разделить все на 32\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        # обрезать полосовым фильтром верхнюю границу в 20 Hz.\n",
    "        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n",
    "\n",
    "        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # Size=(6,)\n",
    "        if self.mode != \"test\":\n",
    "            y_prob = row[CFG.target_cols].values.astype(np.float32)\n",
    "\n",
    "        return X, y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485d0af",
   "metadata": {
    "papermill": {
     "duration": 0.028758,
     "end_time": "2024-03-29T14:18:15.204991",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.176233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fe108f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:15.261585Z",
     "iopub.status.busy": "2024-03-29T14:18:15.261228Z",
     "iopub.status.idle": "2024-03-29T14:18:15.288962Z",
     "shell.execute_reply": "2024-03-29T14:18:15.288077Z"
    },
    "papermill": {
     "duration": 0.058688,
     "end_time": "2024-03-29T14:18:15.291023",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.232335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet_1D_Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        downsampling,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.PReLU()\n",
    "        # self.relu_2 = nn.PReLU()\n",
    "        self.relu_1 = nn.Hardswish()\n",
    "        self.relu_2 = nn.Hardswish()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernels,\n",
    "        in_channels,\n",
    "        fixed_kernel_size,\n",
    "        num_classes,\n",
    "        linear_layer_features,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "    ):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=self.planes,\n",
    "                kernel_size=(kernel_size),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                dilation=dilation,\n",
    "                groups=groups,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.ReLU()\n",
    "        # self.relu_2 = nn.ReLU()\n",
    "        self.relu_1 = nn.SiLU()\n",
    "        self.relu_2 = nn.SiLU()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=self.planes,\n",
    "            out_channels=self.planes,\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.block = self._make_resnet_layer(\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=1,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            padding=fixed_kernel_size // 2,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.in_channels,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            # dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=linear_layer_features, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(\n",
    "        self,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        blocks=9,\n",
    "        padding=0,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "            )\n",
    "            layers.append(\n",
    "                ResNet_1D_Block(\n",
    "                    in_channels=self.planes,\n",
    "                    out_channels=self.planes,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    downsampling=downsampling,\n",
    "                    dilation=dilation,\n",
    "                    groups=groups,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]  # <~~\n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "        return new_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_out = self.extract_features(x)\n",
    "        result = self.fc(new_out)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fc928",
   "metadata": {
    "papermill": {
     "duration": 0.027416,
     "end_time": "2024-03-29T14:18:15.346252",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.318836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009f5388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:15.404890Z",
     "iopub.status.busy": "2024-03-29T14:18:15.404478Z",
     "iopub.status.idle": "2024-03-29T14:18:15.412553Z",
     "shell.execute_reply": "2024-03-29T14:18:15.411545Z"
    },
    "papermill": {
     "duration": 0.040143,
     "end_time": "2024-03-29T14:18:15.414777",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.374634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_function(test_loader, model, device):\n",
    "    model.eval()  # set model in evaluation mode\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    with tqdm(test_loader, unit=\"test_batch\", desc=\"Inference\") as tqdm_test_loader:\n",
    "        for step, batch in enumerate(tqdm_test_loader):\n",
    "            X = batch.pop(\"eeg\").to(device)  # send inputs to `device`\n",
    "            batch_size = X.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)  # forward propagation pass\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())  # save predictions\n",
    "\n",
    "    prediction_dict[\"predictions\"] = np.concatenate(\n",
    "        preds\n",
    "    )  # np.array() of shape (fold_size, target_cols)\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e35b1",
   "metadata": {
    "papermill": {
     "duration": 0.028676,
     "end_time": "2024-03-29T14:18:15.472394",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.443718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62770b4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:15.533473Z",
     "iopub.status.busy": "2024-03-29T14:18:15.533083Z",
     "iopub.status.idle": "2024-03-29T14:18:15.565569Z",
     "shell.execute_reply": "2024-03-29T14:18:15.564569Z"
    },
    "papermill": {
     "duration": 0.066826,
     "end_time": "2024-03-29T14:18:15.568020",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.501194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataframe shape is: (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrogram_id      eeg_id  patient_id\n",
       "0          853520  3911565283        6885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "print(f\"Test dataframe shape is: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b05aa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:15.626603Z",
     "iopub.status.busy": "2024-03-29T14:18:15.626256Z",
     "iopub.status.idle": "2024-03-29T14:18:15.971942Z",
     "shell.execute_reply": "2024-03-29T14:18:15.970910Z"
    },
    "papermill": {
     "duration": 0.378106,
     "end_time": "2024-03-29T14:18:15.974956",
     "exception": false,
     "start_time": "2024-03-29T14:18:15.596850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 raw eeg features\n",
      "['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b672246484e54510acf8a0a4798dad15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_eeg_parquet_paths = glob(CFG.test_eeg + \"*.parquet\")\n",
    "test_eeg_df = pd.read_parquet(test_eeg_parquet_paths[0])\n",
    "test_eeg_features = test_eeg_df.columns\n",
    "print(f\"There are {len(test_eeg_features)} raw eeg features\")\n",
    "print(list(test_eeg_features))\n",
    "del test_eeg_df\n",
    "_ = gc.collect()\n",
    "\n",
    "# %%time\n",
    "all_eegs = {}\n",
    "eeg_ids = test_df.eeg_id.unique()\n",
    "for i, eeg_id in tqdm(enumerate(eeg_ids)):\n",
    "    # Save EEG to Python dictionary of numpy arrays\n",
    "    eeg_path = CFG.test_eeg + str(eeg_id) + \".parquet\"\n",
    "    data = eeg_from_parquet(eeg_path)\n",
    "    all_eegs[eeg_id] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3caa53",
   "metadata": {
    "papermill": {
     "duration": 0.028709,
     "end_time": "2024-03-29T14:18:16.035991",
     "exception": false,
     "start_time": "2024-03-29T14:18:16.007282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2259596b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:16.097327Z",
     "iopub.status.busy": "2024-03-29T14:18:16.096917Z",
     "iopub.status.idle": "2024-03-29T14:18:18.082945Z",
     "shell.execute_reply": "2024-03-29T14:18:18.081800Z"
    },
    "papermill": {
     "duration": 2.019841,
     "end_time": "2024-03-29T14:18:18.085468",
     "exception": false,
     "start_time": "2024-03-29T14:18:16.065627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([2000, 8])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45caab7c443d450e83dbcba9cd27dd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c549a170d5154afe81331e7d294eab61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdd3f54a4bc4022af4804a4e3736aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688d32f7493a46ac9eb444a70a38b2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3227e5736b640e78b1bb72892fcc568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?test_batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "koef_sum = 0\n",
    "koef_count = 0\n",
    "predictions = []\n",
    "files = []\n",
    "    \n",
    "for model_block in model_weights:\n",
    "    test_dataset = EEGDataset(\n",
    "        df=test_df,\n",
    "        batch_size=CFG.batch_size,\n",
    "        mode=\"test\",\n",
    "        eegs=all_eegs,\n",
    "        bandpass_filter=model_block['bandpass_filter']\n",
    "    )\n",
    "\n",
    "    if len(predictions) == 0:\n",
    "        output = test_dataset[0]\n",
    "        X = output[\"eeg\"]\n",
    "        print(f\"X shape: {X.shape}\")\n",
    "                \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    model = EEGNet(\n",
    "        kernels=CFG.kernels,\n",
    "        in_channels=CFG.in_channels,\n",
    "        fixed_kernel_size=CFG.fixed_kernel_size,\n",
    "        num_classes=CFG.target_size,\n",
    "        linear_layer_features=CFG.linear_layer_features,\n",
    "    )\n",
    "\n",
    "    for file_line in model_block['file_data']:\n",
    "        koef = file_line['koef']\n",
    "        for weight_model_file in glob(file_line['file_mask']):\n",
    "            files.append(weight_model_file)\n",
    "            checkpoint = torch.load(weight_model_file, map_location=device)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "            model.to(device)\n",
    "            prediction_dict = inference_function(test_loader, model, device)\n",
    "            predict = prediction_dict[\"predictions\"]\n",
    "            predict *= koef\n",
    "            koef_sum += koef\n",
    "            koef_count += 1\n",
    "            predictions.append(predict)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "koef_sum /= koef_count\n",
    "predictions /= koef_sum\n",
    "predictions = np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9617b385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:18.150929Z",
     "iopub.status.busy": "2024-03-29T14:18:18.150171Z",
     "iopub.status.idle": "2024-03-29T14:18:18.157350Z",
     "shell.execute_reply": "2024-03-29T14:18:18.156322Z"
    },
    "papermill": {
     "duration": 0.041139,
     "end_time": "2024-03-29T14:18:18.159554",
     "exception": false,
     "start_time": "2024-03-29T14:18:18.118415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02019469, 0.0284991 , 0.00893613, 0.07865793, 0.10083617,\n",
       "        0.762876  ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predss_1 = predictions\n",
    "predss_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40dfa7",
   "metadata": {
    "papermill": {
     "duration": 0.030469,
     "end_time": "2024-03-29T14:18:18.220756",
     "exception": false,
     "start_time": "2024-03-29T14:18:18.190287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# >> Model 2 <<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297debe4",
   "metadata": {
    "papermill": {
     "duration": 0.030461,
     "end_time": "2024-03-29T14:18:18.282387",
     "exception": false,
     "start_time": "2024-03-29T14:18:18.251926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Generator, Model and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0068121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:18.345845Z",
     "iopub.status.busy": "2024-03-29T14:18:18.345401Z",
     "iopub.status.idle": "2024-03-29T14:18:32.354845Z",
     "shell.execute_reply": "2024-03-29T14:18:32.353524Z"
    },
    "papermill": {
     "duration": 14.044097,
     "end_time": "2024-03-29T14:18:32.357084",
     "exception": false,
     "start_time": "2024-03-29T14:18:18.312987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "import albumentations as albu\n",
    "from scipy.signal import butter, lfilter\n",
    "import librosa\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import tensorflow.keras.backend as K, gc\n",
    "from tensorflow.keras.layers import Input, Dense, Multiply, Add, Conv1D, Concatenate, LayerNormalization\n",
    "\n",
    "LOAD_BACKBONE_FROM = '/kaggle/input/efficientnetb-tf-keras/EfficientNetB2.h5'\n",
    "LOAD_MODELS_FROM = '/kaggle/input/features-head-starter-models'\n",
    "TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# USE SINGLE GPU, MULTIPLE GPUS \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# WE USE MIXED PRECISION\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "if len(gpus)>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd45acf",
   "metadata": {
    "papermill": {
     "duration": 0.029926,
     "end_time": "2024-03-29T14:18:32.417258",
     "exception": false,
     "start_time": "2024-03-29T14:18:32.387332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236dcde3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:32.480630Z",
     "iopub.status.busy": "2024-03-29T14:18:32.479862Z",
     "iopub.status.idle": "2024-03-29T14:18:32.543133Z",
     "shell.execute_reply": "2024-03-29T14:18:32.542130Z"
    },
    "papermill": {
     "duration": 0.098214,
     "end_time": "2024-03-29T14:18:32.545843",
     "exception": false,
     "start_time": "2024-03-29T14:18:32.447629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "FEAT2IDX = {x:y for x,y in zip(FEATS2,range(len(FEATS2)))}\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2']]\n",
    "USE_PROCESSED = True # Use processed downsampled Raw EEG \n",
    "    \n",
    "class DataGenerator():\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, data, specs=None, eeg_specs=None, raw_eegs=None , augment=False, \n",
    "                 mode='train', data_type='KER'): \n",
    "        self.data = data\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.data_type = data_type\n",
    "        self.specs = specs\n",
    "        self.eeg_specs = eeg_specs\n",
    "        self.raw_eegs = raw_eegs\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.data_generation(index)\n",
    "        if self.augment: X = self.augmentation(X)\n",
    "        return X, y\n",
    "    \n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "            \n",
    "            if i == self.__len__()-1:\n",
    "                self.on_epoch_end()\n",
    "                \n",
    "    def on_epoch_end(self):\n",
    "        if self.mode=='train': \n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def data_generation(self, index):\n",
    "        if self.data_type == 'KE':\n",
    "            X,y = self.generate_all_specs(index)\n",
    "        elif self.data_type == 'E' or self.data_type == 'K':\n",
    "            X,y = self.generate_specs(index)\n",
    "        elif self.data_type == 'R':\n",
    "            X,y = self.generate_raw(index)\n",
    "        elif self.data_type in ['ER','KR']:\n",
    "            X1,y = self.generate_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        elif self.data_type in ['KER']:\n",
    "            X1,y = self.generate_all_specs(index)\n",
    "            X2,y = self.generate_raw(index)\n",
    "            X = (X1,X2)\n",
    "        return X,y\n",
    "    \n",
    "    def generate_all_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "        \n",
    "        eeg = self.eeg_specs[row.eeg_id]\n",
    "        spec = self.specs[row.spec_id]\n",
    "        \n",
    "        imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "        img = np.stack(imgs,axis=-1)\n",
    "        # LOG TRANSFORM SPECTROGRAM\n",
    "        img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "        img = np.log(img)\n",
    "            \n",
    "        # STANDARDIZE PER IMAGE\n",
    "        img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3] # RP_k\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2] # RL_k\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1] # LP_k\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0] # LL_k\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,2] # RL_k\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,1] # LP_k\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3] # RP_K\n",
    "        \n",
    "        # EEG\n",
    "        img = eeg\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3] # RP_e\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,2] # RL_e\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,1] # LP_e\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0] # LL_e\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2] # RL_e\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1] # LP_e\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3] # RP_e\n",
    "\n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_specs(self, index):\n",
    "        X = np.zeros((512,512,3),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset/2)\n",
    "            \n",
    "        if self.data_type in ['E','ER']:\n",
    "            img = self.eeg_specs[row.eeg_id]\n",
    "        elif self.data_type in ['K','KR']:\n",
    "            spec = self.specs[row.spec_id]\n",
    "            imgs = [spec[offset:offset+300,k*100:(k+1)*100].T for k in [0,2,1,3]] # to match kaggle with eeg\n",
    "            img = np.stack(imgs,axis=-1)\n",
    "            # LOG TRANSFORM SPECTROGRAM\n",
    "            img = np.clip(img,np.exp(-4),np.exp(8))\n",
    "            img = np.log(img)\n",
    "            \n",
    "            # STANDARDIZE PER IMAGE\n",
    "            img = np.nan_to_num(img, nan=0.0)    \n",
    "            \n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        \n",
    "        X[0_0+56:100+56,:256,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,:256,0] = img[:,22:-22,2]\n",
    "        X[0_0+56:100+56,:256,1] = img[:,22:-22,1]\n",
    "        X[100+56:200+56,:256,1] = img[:,22:-22,3]\n",
    "        X[0_0+56:100+56,:256,2] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,:256,2] = img[:,22:-22,1]\n",
    "        \n",
    "        X[0_0+56:100+56,256:,0] = img[:,22:-22,0]\n",
    "        X[100+56:200+56,256:,0] = img[:,22:-22,1]\n",
    "        X[0_0+56:100+56,256:,1] = img[:,22:-22,2]\n",
    "        X[100+56:200+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        X[200+56:300+56,:256,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,:256,0] = img[:,22:-22,1]\n",
    "        X[200+56:300+56,:256,1] = img[:,22:-22,2]\n",
    "        X[300+56:400+56,:256,1] = img[:,22:-22,3]\n",
    "        X[200+56:300+56,:256,2] = img[:,22:-22,3]\n",
    "        X[300+56:400+56,:256,2] = img[:,22:-22,2]\n",
    "        \n",
    "        X[200+56:300+56,256:,0] = img[:,22:-22,0]\n",
    "        X[300+56:400+56,256:,0] = img[:,22:-22,2]\n",
    "        X[200+56:300+56,256:,1] = img[:,22:-22,1]\n",
    "        X[300+56:400+56,256:,1] = img[:,22:-22,3]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def generate_raw(self,index):\n",
    "        if USE_PROCESSED and self.mode!='test':\n",
    "            X = np.zeros((2_000,8),dtype='float32')\n",
    "            y = np.zeros((6,),dtype='float32')\n",
    "            row = self.data.iloc[index]\n",
    "            X = self.raw_eegs[row.eeg_id]\n",
    "            y[:] = row[TARGETS]\n",
    "            return X,y\n",
    "        \n",
    "        X = np.zeros((10_000,8),dtype='float32')\n",
    "        y = np.zeros((6,),dtype='float32')\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        eeg = self.raw_eegs[row.eeg_id]\n",
    "            \n",
    "        # FEATURE ENGINEER\n",
    "        X[:,0] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['T3']]\n",
    "        X[:,1] = eeg[:,FEAT2IDX['T3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,2] = eeg[:,FEAT2IDX['Fp1']] - eeg[:,FEAT2IDX['C3']]\n",
    "        X[:,3] = eeg[:,FEAT2IDX['C3']] - eeg[:,FEAT2IDX['O1']]\n",
    "            \n",
    "        X[:,4] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['C4']]\n",
    "        X[:,5] = eeg[:,FEAT2IDX['C4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        X[:,6] = eeg[:,FEAT2IDX['Fp2']] - eeg[:,FEAT2IDX['T4']]\n",
    "        X[:,7] = eeg[:,FEAT2IDX['T4']] - eeg[:,FEAT2IDX['O2']]\n",
    "            \n",
    "        # STANDARDIZE\n",
    "        X = np.clip(X,-1024,1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "            \n",
    "        # BUTTER LOW-PASS FILTER\n",
    "        X = self.butter_lowpass_filter(X)\n",
    "        # Downsample\n",
    "        X = X[::5,:]\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            y[:] = row[TARGETS]\n",
    "                \n",
    "        return X,y\n",
    "        \n",
    "    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "        return filtered_data\n",
    "    \n",
    "    def resize(self, img,size):\n",
    "        composition = albu.Compose([\n",
    "                albu.Resize(size[0],size[1])\n",
    "            ])\n",
    "        return composition(image=img)['image']\n",
    "            \n",
    "    def augmentation(self, img):\n",
    "        composition = albu.Compose([\n",
    "                albu.HorizontalFlip(p=0.4)\n",
    "            ])\n",
    "        return composition(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f9e2ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:32.608122Z",
     "iopub.status.busy": "2024-03-29T14:18:32.607703Z",
     "iopub.status.idle": "2024-03-29T14:18:43.775033Z",
     "shell.execute_reply": "2024-03-29T14:18:43.773484Z"
    },
    "papermill": {
     "duration": 11.203941,
     "end_time": "2024-03-29T14:18:43.779509",
     "exception": false,
     "start_time": "2024-03-29T14:18:32.575568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (1, 3)\n",
      "There are 1 test spectrogram parquets\n",
      "Converting Test EEG to Spectrograms...\n",
      "Processing Test EEG parquets...\n"
     ]
    }
   ],
   "source": [
    "def spectrogram_from_eeg(parquet_path):    \n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg)-10_000)//2\n",
    "    eeg = eeg.iloc[middle:middle+10_000]\n",
    "    \n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((100,300,4),dtype='float32')\n",
    "\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "        \n",
    "        for kk in range(4):\n",
    "            # FILL NANS\n",
    "            x1 = eeg[COLS[kk]].values\n",
    "            x2 = eeg[COLS[kk+1]].values\n",
    "            m = np.nanmean(x1)\n",
    "            if np.isnan(x1).mean()<1: x1 = np.nan_to_num(x1,nan=m)\n",
    "            else: x1[:] = 0\n",
    "            m = np.nanmean(x2)\n",
    "            if np.isnan(x2).mean()<1: x2 = np.nan_to_num(x2,nan=m)\n",
    "            else: x2[:] = 0\n",
    "                \n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = x1 - x2\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//300, \n",
    "                  n_fft=1024, n_mels=100, fmin=0, fmax=20, win_length=128)\n",
    "            \n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1]//30)*30\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
    "            img[:,:,k] += mel_spec_db\n",
    "                \n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:,:,k] /= 4.0\n",
    "          \n",
    "    return img\n",
    "\n",
    "def eeg_from_parquet(parquet_path):\n",
    "\n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows-10_000)//2\n",
    "    eeg = eeg.iloc[offset:offset+10_000]\n",
    "    data = np.zeros((10_000,len(FEATS2)))\n",
    "    for j,col in enumerate(FEATS2):\n",
    "        \n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype('float32')\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
    "        else: x[:] = 0\n",
    "        \n",
    "        data[:,j] = x\n",
    "\n",
    "    return data\n",
    "# Load testing features\n",
    "test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
    "# Rename\n",
    "test = test.rename({'spectrogram_id':'spec_id'},axis=1)\n",
    "print('Test shape',test.shape)\n",
    "test.head()\n",
    "# Read all spectrograms\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms'\n",
    "files = os.listdir(PATH)\n",
    "print(f'There are {len(files)} test spectrogram parquets')\n",
    "spectrograms = {}\n",
    "for i,f in enumerate(files):\n",
    "    tmp = pd.read_parquet(f'{PATH}/{f}')\n",
    "    name = int(f.split('.')[0])\n",
    "    spectrograms[name] = tmp.iloc[:,1:].values\n",
    "# Read all EEG Spectrograms\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "DISPLAY = 0\n",
    "EEG_IDS = test.eeg_id.unique()\n",
    "all_eegs = {}\n",
    "print('Converting Test EEG to Spectrograms...')\n",
    "for i,eeg_id in enumerate(EEG_IDS):\n",
    "    # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "    img = spectrogram_from_eeg(f'{PATH}/{eeg_id}.parquet')\n",
    "    all_eegs[eeg_id] = img\n",
    "# Read all RAW EEG Signals\n",
    "all_raw_eegs = {}\n",
    "EEG_IDS = test.eeg_id.unique()\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs'\n",
    "print('Processing Test EEG parquets...')\n",
    "for i,eeg_id in enumerate(EEG_IDS):\n",
    "    # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n",
    "    data = eeg_from_parquet(f'{PATH}/{eeg_id}.parquet')\n",
    "    all_raw_eegs[eeg_id] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60785fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:43.900101Z",
     "iopub.status.busy": "2024-03-29T14:18:43.898875Z",
     "iopub.status.idle": "2024-03-29T14:18:43.906769Z",
     "shell.execute_reply": "2024-03-29T14:18:43.905793Z"
    },
    "papermill": {
     "duration": 0.058717,
     "end_time": "2024-03-29T14:18:43.909022",
     "exception": false,
     "start_time": "2024-03-29T14:18:43.850305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_TYPE = 'KER' # K|E|R|KE|KR|ER|KER\n",
    "# Submission ON TEST without ensemble\n",
    "def preds_without_ensemble(VER=50):\n",
    "    preds = []\n",
    "    \n",
    "    test_dataset = dataset(test,mode='test',specs=spectrograms2, eeg_specs=all_eegs2, raw_eegs=all_raw_eegs2)\n",
    "    model = build_model()\n",
    "\n",
    "    for i in range(5):\n",
    "        print(f'Fold {i+1}')\n",
    "        model.load_weights(f'{LOAD_MODELS_FROM}/model_{DATA_TYPE}_{VER}_{i}.weights.h5')\n",
    "        pred = model.predict(test_dataset, verbose=1)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    pred = np.mean(preds,axis=0)\n",
    "    print('Test preds shape',pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a71bd176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:43.973147Z",
     "iopub.status.busy": "2024-03-29T14:18:43.972478Z",
     "iopub.status.idle": "2024-03-29T14:18:43.978598Z",
     "shell.execute_reply": "2024-03-29T14:18:43.977659Z"
    },
    "papermill": {
     "duration": 0.040627,
     "end_time": "2024-03-29T14:18:43.980648",
     "exception": false,
     "start_time": "2024-03-29T14:18:43.940021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup for ensemble\n",
    "ENSEMBLE = True\n",
    "#LBs = [0.41,0.39,0.41,0.37,0.39,0.38,0.36] # K|E|R|KE|KR|ER|KER for weighted ensemble we use LBs of each model\n",
    "LBs = [0.81,0.79,0.81,0.77,0.79,0.78,0.76]\n",
    "VER_K = 43 # Kaggle's spectrogram model version\n",
    "VER_E = 42 # EEG's spectrogram model version\n",
    "VER_R = 60 #37 # EEG's Raw wavenet model version, trained on single GPU\n",
    "VER_KE = 58 #47 # Kaggle's and EEG's spectrogram model version\n",
    "VER_KR = 48 # Kaggle's spectrogram and Raw model version\n",
    "VER_ER = 49 # EEG's spectrogram and Raw model version\n",
    "VER_KER = 50 # EEG's, Kaggle's spectrograms and Raw model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781a07cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:44.041607Z",
     "iopub.status.busy": "2024-03-29T14:18:44.040992Z",
     "iopub.status.idle": "2024-03-29T14:18:44.050705Z",
     "shell.execute_reply": "2024-03-29T14:18:44.049907Z"
    },
    "papermill": {
     "duration": 0.041923,
     "end_time": "2024-03-29T14:18:44.052753",
     "exception": false,
     "start_time": "2024-03-29T14:18:44.010830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(data, mode='train', batch_size=8, data_type=DATA_TYPE, \n",
    "            augment=False, specs=None, eeg_specs=None, raw_eegs=None):\n",
    "    \n",
    "    BATCH_SIZE_PER_REPLICA = batch_size\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "    gen = DataGenerator(data,mode=mode, data_type=data_type, augment=augment,\n",
    "                       specs=specs, eeg_specs=eeg_specs, raw_eegs=raw_eegs)\n",
    "    if data_type in ['K','E','KE']: \n",
    "        inp = tf.TensorSpec(shape=(512,512,3), dtype=tf.float32)\n",
    "    elif data_type in ['KR','ER','KER']:\n",
    "        inp = (tf.TensorSpec(shape=(512,512,3), dtype=tf.float32),tf.TensorSpec(shape=(2000,8), dtype=tf.float32))\n",
    "    elif data_type in ['R']:\n",
    "        inp = tf.TensorSpec(shape=(2000,8), dtype=tf.float32)\n",
    "        \n",
    "    output_signature = (inp,tf.TensorSpec(shape=(6,), dtype=tf.float32))\n",
    "    dataset = tf.data.Dataset.from_generator(generator=gen, output_signature=output_signature).batch(\n",
    "        BATCH_SIZE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66570f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:44.112304Z",
     "iopub.status.busy": "2024-03-29T14:18:44.111930Z",
     "iopub.status.idle": "2024-03-29T14:18:44.136429Z",
     "shell.execute_reply": "2024-03-29T14:18:44.135625Z"
    },
    "papermill": {
     "duration": 0.057237,
     "end_time": "2024-03-29T14:18:44.138395",
     "exception": false,
     "start_time": "2024-03-29T14:18:44.081158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_spec_model(hybrid=False):  \n",
    "    inp = tf.keras.layers.Input((512,512,3))\n",
    "    base_model = load_model(f'{LOAD_BACKBONE_FROM}')    \n",
    "    x = base_model(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if not hybrid:\n",
    "        x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer=opt)  \n",
    "    return model\n",
    "\n",
    "def build_wave_model(hybrid=False):\n",
    "    def wave_block(x, filters, kernel_size, n):\n",
    "        dilation_rates = [2**i for i in range(n)]\n",
    "        x = Conv1D(filters = filters,\n",
    "                   kernel_size = 1,\n",
    "                   padding = 'same')(x)\n",
    "        res_x = x\n",
    "        for dilation_rate in dilation_rates:\n",
    "            tanh_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same', \n",
    "                              activation = 'tanh', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            sigm_out = Conv1D(filters = filters,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = 'same',\n",
    "                              activation = 'sigmoid', \n",
    "                              dilation_rate = dilation_rate)(x)\n",
    "            x = Multiply()([tanh_out, sigm_out])\n",
    "            x = Conv1D(filters = filters,\n",
    "                       kernel_size = 1,\n",
    "                       padding = 'same')(x)\n",
    "            res_x = Add()([res_x, x])\n",
    "        return res_x\n",
    "    \n",
    "        \n",
    "    # INPUT \n",
    "    inp = tf.keras.Input(shape=(2_000,8))\n",
    "    \n",
    "    ############\n",
    "    # FEATURE EXTRACTION SUB MODEL\n",
    "    inp2 = tf.keras.Input(shape=(2_000,1))\n",
    "    x = wave_block(inp2, 8, 4, 6)\n",
    "    x = wave_block(x, 16, 4, 6)\n",
    "    x = wave_block(x, 32, 4, 6)\n",
    "    x = wave_block(x, 64, 4, 6)\n",
    "    model2 = tf.keras.Model(inputs=inp2, outputs=x)\n",
    "    ###########\n",
    "    \n",
    "    # LEFT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:,:,0:1])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,1:2])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z1 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # LEFT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:,:,2:3])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,3:4])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z2 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # RIGHT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:,:,4:5])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,5:6])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z3 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # RIGHT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:,:,6:7])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:,:,7:8])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z4 = tf.keras.layers.Average()([x1,x2])\n",
    "    \n",
    "    # COMBINE CHAINS\n",
    "    y = tf.keras.layers.Concatenate()([z1,z2,z3,z4])\n",
    "    if not hybrid:\n",
    "        y = tf.keras.layers.Dense(64, activation='relu')(y)\n",
    "        y = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(y)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inp, outputs=y)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer = opt)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_hybrid_model():\n",
    "    model_spec = build_spec_model(True)\n",
    "    model_wave = build_wave_model(True)\n",
    "    inputs = [model_spec.input, model_wave.input]\n",
    "    x = [model_spec.output, model_wave.output]\n",
    "    x = tf.keras.layers.Concatenate()(x)\n",
    "    x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer = opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86c24be9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:18:44.200088Z",
     "iopub.status.busy": "2024-03-29T14:18:44.199683Z",
     "iopub.status.idle": "2024-03-29T14:21:16.384317Z",
     "shell.execute_reply": "2024-03-29T14:21:16.383144Z"
    },
    "papermill": {
     "duration": 152.218536,
     "end_time": "2024-03-29T14:21:16.386889",
     "exception": false,
     "start_time": "2024-03-29T14:18:44.168353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 14s 14s/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Fold 2\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Fold 3\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "Fold 4\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "Fold 5\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Test preds shape (1, 6)\n"
     ]
    }
   ],
   "source": [
    "# Submission ON TEST with ensemble\n",
    "def preds_with_ensemble():\n",
    "    preds = []\n",
    "    params = {'specs':spectrograms, 'eeg_specs':all_eegs, 'raw_eegs':all_raw_eegs}\n",
    "    test_dataset_K = create_dataset(test, data_type='K', mode='test', **params)\n",
    "    test_dataset_E = create_dataset(test, data_type='E', mode='test', **params)\n",
    "    test_dataset_R = create_dataset(test, data_type='R', mode='test', **params)\n",
    "    test_dataset_KE = create_dataset(test, data_type='KE', mode='test', **params)\n",
    "    test_dataset_KR = create_dataset(test, data_type='KR', mode='test', **params)\n",
    "    test_dataset_ER = create_dataset(test, data_type='ER', mode='test', **params)\n",
    "    test_dataset_KER = create_dataset(test, data_type='KER', mode='test', **params)\n",
    "\n",
    "    # LB SCORE WEIGHTS FOR EACH MODEL\n",
    "    lbs = 1 - np.array(LBs)\n",
    "    weights = lbs/lbs.sum()\n",
    "    model_spec = build_spec_model()\n",
    "    model_wave = build_wave_model()\n",
    "    model_hybrid = build_hybrid_model()\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(f'Fold {i+1}')\n",
    "        # Kaggle's spectrogram model \n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_K_{VER_K}_{i}.weights.h5')\n",
    "        pred_K = model_spec.predict(test_dataset_K, verbose=1)\n",
    "        # EEG's spectrogram model\n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_E_{VER_E}_{i}.weights.h5')\n",
    "        pred_E = model_spec.predict(test_dataset_E, verbose=1)\n",
    "        # EEG's Raw wavenet model\n",
    "        model_wave.load_weights(f'{LOAD_MODELS_FROM}/model_R_{VER_R}_{i}.weights.h5')\n",
    "        pred_R = model_wave.predict(test_dataset_R, verbose=1)\n",
    "        # Kaggle's and EEG's spectrogram model\n",
    "        model_spec.load_weights(f'{LOAD_MODELS_FROM}/model_KE_{VER_KE}_{i}.weights.h5')\n",
    "        pred_KE = model_spec.predict(test_dataset_KE, verbose=1)\n",
    "        # Kaggle's spectrogram and Raw model\n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KR_{VER_KR}_{i}.weights.h5')\n",
    "        pred_KR = model_hybrid.predict(test_dataset_KR, verbose=1)\n",
    "        # EEG's spectrogram and Raw model\n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_ER_{VER_ER}_{i}.weights.h5')\n",
    "        pred_ER = model_hybrid.predict(test_dataset_ER, verbose=1)\n",
    "        # EEG's, Kaggle's spectrograms and Raw model\n",
    "        model_hybrid.load_weights(f'{LOAD_MODELS_FROM}/model_KER_{VER_KER}_{i}.weights.h5')\n",
    "        pred_KER = model_hybrid.predict(test_dataset_KER, verbose=1)\n",
    "        # Combine the predictions from all the model with different weights \n",
    "        pred = np.array([pred_K,pred_E,pred_R,pred_KE,pred_KR,pred_ER,pred_KER])\n",
    "        pred = np.average(pred,axis=0,weights=weights)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    pred = np.mean(preds,axis=0)\n",
    "    return pred\n",
    "\n",
    "# Prediction with \n",
    "pred = preds_with_ensemble()\n",
    "print('Test preds shape',pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b5adb",
   "metadata": {
    "papermill": {
     "duration": 0.039432,
     "end_time": "2024-03-29T14:21:16.465368",
     "exception": false,
     "start_time": "2024-03-29T14:21:16.425936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c45cf80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:16.543693Z",
     "iopub.status.busy": "2024-03-29T14:21:16.542637Z",
     "iopub.status.idle": "2024-03-29T14:21:16.550137Z",
     "shell.execute_reply": "2024-03-29T14:21:16.549218Z"
    },
    "papermill": {
     "duration": 0.050323,
     "end_time": "2024-03-29T14:21:16.553462",
     "exception": false,
     "start_time": "2024-03-29T14:21:16.503139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05228921, 0.05957175, 0.00158099, 0.38807301, 0.02695576,\n",
       "        0.47152926]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predss_2 = pred\n",
    "predss_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99afe0fd",
   "metadata": {
    "papermill": {
     "duration": 0.038218,
     "end_time": "2024-03-29T14:21:16.633970",
     "exception": false,
     "start_time": "2024-03-29T14:21:16.595752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# >>Model 3<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd96d698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:16.712562Z",
     "iopub.status.busy": "2024-03-29T14:21:16.712163Z",
     "iopub.status.idle": "2024-03-29T14:21:19.754669Z",
     "shell.execute_reply": "2024-03-29T14:21:19.753602Z"
    },
    "papermill": {
     "duration": 3.084659,
     "end_time": "2024-03-29T14:21:19.756894",
     "exception": false,
     "start_time": "2024-03-29T14:21:16.672235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import timm  \n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "warnings.filterwarnings('ignore', category=Warning)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e067fd0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:19.836259Z",
     "iopub.status.busy": "2024-03-29T14:21:19.835214Z",
     "iopub.status.idle": "2024-03-29T14:21:19.844992Z",
     "shell.execute_reply": "2024-03-29T14:21:19.844014Z"
    },
    "papermill": {
     "duration": 0.051404,
     "end_time": "2024-03-29T14:21:19.847305",
     "exception": false,
     "start_time": "2024-03-29T14:21:19.795901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 3131\n",
    "    image_transform = transforms.Resize((512, 512))\n",
    "    num_folds = 5\n",
    "    dataset_wide_mean = -0.2972692229201065 #From Train notebook\n",
    "    dataset_wide_std = 2.5997336315611026 #From Train notebook\n",
    "    ownspec_mean = 7.29084372799223e-05 # From Train spectrograms notebook\n",
    "    ownspec_std = 4.510082606216031 # From Train spectrograms notebook\n",
    "    \n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(Config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c26dd1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:19.923247Z",
     "iopub.status.busy": "2024-03-29T14:21:19.922531Z",
     "iopub.status.idle": "2024-03-29T14:21:20.352987Z",
     "shell.execute_reply": "2024-03-29T14:21:20.352045Z"
    },
    "papermill": {
     "duration": 0.470476,
     "end_time": "2024-03-29T14:21:20.355126",
     "exception": false,
     "start_time": "2024-03-29T14:21:19.884650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path_spec</th>\n",
       "      <th>path_eeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>853520</td>\n",
       "      <td>6885</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "      <td>/kaggle/input/hms-harmful-brain-activity-class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.166667  0.166667  0.166667   0.166667   0.166667   \n",
       "\n",
       "   other_vote  spectrogram_id  patient_id  \\\n",
       "0    0.166667          853520        6885   \n",
       "\n",
       "                                           path_spec  \\\n",
       "0  /kaggle/input/hms-harmful-brain-activity-class...   \n",
       "\n",
       "                                            path_eeg  \n",
       "0  /kaggle/input/hms-harmful-brain-activity-class...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n",
    "\n",
    "submission = submission.merge(test_df, on='eeg_id', how='left')\n",
    "submission['path_spec'] = submission['spectrogram_id'].apply(lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/{x}.parquet\")\n",
    "submission['path_eeg'] = submission['eeg_id'].apply(lambda x: f\"/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/{x}.parquet\")\n",
    "\n",
    "display(submission)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61924940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:20.430351Z",
     "iopub.status.busy": "2024-03-29T14:21:20.429992Z",
     "iopub.status.idle": "2024-03-29T14:21:26.379205Z",
     "shell.execute_reply": "2024-03-29T14:21:26.378178Z"
    },
    "papermill": {
     "duration": 5.989837,
     "end_time": "2024-03-29T14:21:26.381424",
     "exception": false,
     "start_time": "2024-03-29T14:21:20.391587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "# Load in original EfficientnetB0 model\n",
    "for i in range(Config.num_folds):\n",
    "    model_effnet_b0 = timm.create_model('efficientnet_b0', pretrained=False, num_classes=6, in_chans=1)\n",
    "    model_effnet_b0.load_state_dict(torch.load(f'/kaggle/input/hms-train-efficientnetb0/efficientnet_b0_fold{i}.pth', map_location=torch.device('cpu')))\n",
    "    models.append(model_effnet_b0)\n",
    "    \n",
    "models_datawide = []\n",
    "# Load in hyperparameter optimized EfficientnetB1\n",
    "for i in range(Config.num_folds):\n",
    "    model_effnet_b1 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n",
    "    model_effnet_b1.load_state_dict(torch.load(f'/kaggle/input/train/efficientnet_b1_fold{i}.pth', map_location=torch.device('cpu')))\n",
    "    models_datawide.append(model_effnet_b1)\n",
    "    \n",
    "models_ownspec = []\n",
    "# Load in EfficientnetB1 with new spectrograms\n",
    "for i in range(Config.num_folds):\n",
    "    model_effnet_b1 = timm.create_model('efficientnet_b1', pretrained=False, num_classes=6, in_chans=1)\n",
    "    model_effnet_b1.load_state_dict(torch.load(f'/kaggle/input/efficientnet-b1-ownspectrograms/efficientnet_b1_fold{i}_datawide_CosineAnnealingLR_0.001_False.pth', map_location=torch.device('cpu')))\n",
    "    models_ownspec.append(model_effnet_b1)\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61792652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:26.458221Z",
     "iopub.status.busy": "2024-03-29T14:21:26.457840Z",
     "iopub.status.idle": "2024-03-29T14:21:30.053107Z",
     "shell.execute_reply": "2024-03-29T14:21:30.052200Z"
    },
    "papermill": {
     "duration": 3.636371,
     "end_time": "2024-03-29T14:21:30.055239",
     "exception": false,
     "start_time": "2024-03-29T14:21:26.418868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = []\n",
    "\n",
    "def create_spectrogram(data):\n",
    "    \"\"\"This function will create a spectrogram based on EEG-data\"\"\"\n",
    "    nperseg = 150  # Length of each segment\n",
    "    noverlap = 128  # Overlap between segments\n",
    "    NFFT = max(256, 2 ** int(np.ceil(np.log2(nperseg))))\n",
    "\n",
    "    # LL Spec = ( spec(Fp1 - F7) + spec(F7 - T3) + spec(T3 - T5) + spec(T5 - O1) )/4\n",
    "    freqs, t,spectrum_LL1 = signal.spectrogram(data['Fp1']-data['F7'],nfft=NFFT,noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_LL2 = signal.spectrogram(data['F7']-data['T3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_LL3 = signal.spectrogram(data['T3']-data['T5'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_LL4 = signal.spectrogram(data['T5']-data['O1'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "\n",
    "    LL = (spectrum_LL1+ spectrum_LL2 +spectrum_LL3 + spectrum_LL4)/4\n",
    "\n",
    "    # LP Spec = ( spec(Fp1 - F3) + spec(F3 - C3) + spec(C3 - P3) + spec(P3 - O1) )/4\n",
    "    freqs, t,spectrum_LP1 = signal.spectrogram(data['Fp1']-data['F3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_LP2 = signal.spectrogram(data['F3']-data['C3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_LP3 = signal.spectrogram(data['C3']-data['P3'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_LP4 = signal.spectrogram(data['P3']-data['O1'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "\n",
    "    LP = (spectrum_LP1+ spectrum_LP2 +spectrum_LP3 + spectrum_LP4)/4\n",
    "\n",
    "    # RP Spec = ( spec(Fp2 - F4) + spec(F4 - C4) + spec(C4 - P4) + spec(P4 - O2) )/4\n",
    "    freqs, t,spectrum_RP1 = signal.spectrogram(data['Fp2']-data['F4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_RP2 = signal.spectrogram(data['F4']-data['C4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_RP3 = signal.spectrogram(data['C4']-data['P4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_RP4 = signal.spectrogram(data['P4']-data['O2'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "\n",
    "    RP = (spectrum_RP1+ spectrum_RP2 +spectrum_RP3 + spectrum_RP4)/4\n",
    "\n",
    "\n",
    "    # RL Spec = ( spec(Fp2 - F8) + spec(F8 - T4) + spec(T4 - T6) + spec(T6 - O2) )/4\n",
    "    freqs, t,spectrum_RL1 = signal.spectrogram(data['Fp2']-data['F8'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_RL2 = signal.spectrogram(data['F8']-data['T4'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_RL3 = signal.spectrogram(data['T4']-data['T6'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    freqs, t,spectrum_RL4 = signal.spectrogram(data['T6']-data['O2'],nfft=NFFT, noverlap = noverlap,nperseg=nperseg)\n",
    "    RL = (spectrum_RL1+ spectrum_RL2 +spectrum_RL3 + spectrum_RL4)/4\n",
    "    spectogram = np.concatenate((LL, LP,RP,RL), axis=0)\n",
    "    return spectogram\n",
    "\n",
    "def preprocess_ownspec(path_to_parquet):\n",
    "    \"\"\"The data will be processed from EEG to spectrogramdata\"\"\"\n",
    "    data = pd.read_parquet(path_to_parquet)\n",
    "    data = create_spectrogram(data)\n",
    "    mask = np.isnan(data)\n",
    "    data[mask] = -1\n",
    "    data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "    data = np.log(data)\n",
    "    \n",
    "    return data \n",
    "\n",
    "def preprocess(path_to_parquet):\n",
    "    data = pd.read_parquet(path_to_parquet)\n",
    "    data = data.fillna(-1).values[:, 1:].T\n",
    "    data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "    data = np.log(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_datawide(data_point):\n",
    "    \"\"\"The spectrogram data will be normalized data wide.\"\"\"\n",
    "    eps = 1e-6\n",
    "\n",
    "    data_point = (data_point - Config.dataset_wide_mean) / (Config.dataset_wide_std + eps)\n",
    "\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data_point), dim=0)\n",
    "    data_point = Config.image_transform(data_tensor)\n",
    "\n",
    "    return data_point\n",
    "\n",
    "\n",
    "def normalize_datawide_ownspec(data):\n",
    "    \"\"\"The new spectrogram data will be normalized data wide.\"\"\"\n",
    "    eps = 1e-6\n",
    "    \n",
    "    data = (data - Config.ownspec_mean) / (Config.ownspec_std + eps)\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "    data = Config.image_transform(data_tensor)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_instance_wise(data_point):\n",
    "    \"\"\"The spectrogram data will be normalized instance wise.\"\"\"\n",
    "    eps = 1e-6\n",
    "    \n",
    "    data_mean = data_point.mean(axis=(0, 1))\n",
    "    data_std = data_point.std(axis=(0, 1))\n",
    "    data_point = (data_point - data_mean) / (data_std + eps)\n",
    "    \n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data_point), dim=0)\n",
    "    data_point = Config.image_transform(data_tensor)\n",
    "    \n",
    "    return data_point\n",
    "\n",
    "# Loop over samples\n",
    "for index in submission.index:\n",
    "    test_predictions_per_model = []\n",
    "    \n",
    "    preprocessed_data = preprocess(submission.iloc[index]['path_spec'])\n",
    "    preprocessed_data_ownspec = preprocess_ownspec(submission.iloc[index]['path_eeg'])\n",
    "    \n",
    "    # Predict based on original EfficientnetB0 models. \n",
    "    for i in range(len(models)):\n",
    "        models[i].eval()\n",
    "        \n",
    "        current_parquet_data = normalize_instance_wise(preprocessed_data).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = models[i](current_parquet_data)\n",
    "            current_model_prediction = F.softmax(model_output)[0].detach().cpu().numpy()\n",
    "            \n",
    "        test_predictions_per_model.append(current_model_prediction)\n",
    "    \n",
    "    # Predict based on hyperparameter optimized EffcientnetB1.\n",
    "    for i in range(len(models_datawide)):\n",
    "        models_datawide[i].eval()\n",
    "        \n",
    "        current_parquet_data = normalize_datawide(preprocessed_data).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = models_datawide[i](current_parquet_data)\n",
    "            current_model_prediction = F.softmax(model_output)[0].detach().cpu().numpy()\n",
    "            \n",
    "        test_predictions_per_model.append(current_model_prediction)\n",
    "    \n",
    "    # Predict based on EfficientnetB1 model with new spectrograms.\n",
    "    for i in range(len(models_ownspec)):\n",
    "        models_ownspec[i].eval()\n",
    "        \n",
    "        current_parquet_data = normalize_datawide_ownspec(preprocessed_data_ownspec).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model_output = models_ownspec[i](current_parquet_data)\n",
    "            current_model_prediction = F.softmax(model_output)[0].detach().cpu().numpy()\n",
    "            \n",
    "        test_predictions_per_model.append(current_model_prediction)\n",
    "    \n",
    "    # The mean of all models is taken.\n",
    "    ensemble_prediction = np.mean(test_predictions_per_model,axis=0)\n",
    "    \n",
    "    test_predictions.append(ensemble_prediction)\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "394bc098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:30.131452Z",
     "iopub.status.busy": "2024-03-29T14:21:30.131056Z",
     "iopub.status.idle": "2024-03-29T14:21:30.137900Z",
     "shell.execute_reply": "2024-03-29T14:21:30.137006Z"
    },
    "papermill": {
     "duration": 0.048092,
     "end_time": "2024-03-29T14:21:30.140293",
     "exception": false,
     "start_time": "2024-03-29T14:21:30.092201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03419812, 0.07484972, 0.001024  , 0.38697532, 0.01671714,\n",
       "        0.48623565]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predss_3 = test_predictions\n",
    "predss_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa5812",
   "metadata": {
    "papermill": {
     "duration": 0.037481,
     "end_time": "2024-03-29T14:21:30.217569",
     "exception": false,
     "start_time": "2024-03-29T14:21:30.180088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission Model 1 + Model 2 + Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91cb2614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:30.296780Z",
     "iopub.status.busy": "2024-03-29T14:21:30.295943Z",
     "iopub.status.idle": "2024-03-29T14:21:30.316698Z",
     "shell.execute_reply": "2024-03-29T14:21:30.315666Z"
    },
    "papermill": {
     "duration": 0.063001,
     "end_time": "2024-03-29T14:21:30.319045",
     "exception": false,
     "start_time": "2024-03-29T14:21:30.256044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.03061</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.248397</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.608518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283       0.03061    0.0517  0.004668   0.248397   0.056106   \n",
       "\n",
       "   other_vote  \n",
       "0    0.608518  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission=pd.read_csv(\"/kaggle/input/hms-harmful-brain-activity-classification/sample_submission.csv\")\n",
    "labels=['seizure','lpd','gpd','lrda','grda','other']\n",
    "for i in range(len(labels)):\n",
    "    submission[f'{labels[i]}_vote']=(predss_1[:,i] * 0.45 + predss_2[:, i] * 0.15 + predss_3[:, i] * 0.40)\n",
    "submission.to_csv(\"submission.csv\",index=None)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5906d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T14:21:30.400180Z",
     "iopub.status.busy": "2024-03-29T14:21:30.399812Z",
     "iopub.status.idle": "2024-03-29T14:21:30.410961Z",
     "shell.execute_reply": "2024-03-29T14:21:30.409354Z"
    },
    "papermill": {
     "duration": 0.056904,
     "end_time": "2024-03-29T14:21:30.414087",
     "exception": false,
     "start_time": "2024-03-29T14:21:30.357183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "submission.iloc[:,-6:].sum(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4382744,
     "sourceId": 7752462,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4571300,
     "sourceId": 7805987,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4574876,
     "sourceId": 7810897,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4576535,
     "sourceId": 7813071,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4618382,
     "sourceId": 7870824,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4619437,
     "sourceId": 7872459,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4417235,
     "isSourceIdPinned": true,
     "sourceId": 7946649,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 160674831,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 160700706,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 165876189,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 209.852289,
   "end_time": "2024-03-29T14:21:33.840786",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-29T14:18:03.988497",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08c5b48c1dc04603a0795392a4cb6f8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a7ad8e7bc5d460b8b4714bc6fe65b26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_08c5b48c1dc04603a0795392a4cb6f8b",
       "placeholder": "​",
       "style": "IPY_MODEL_c82e29dce373416dbaeb74eaacd7e847",
       "value": " 1/1 [00:00&lt;00:00, 33.41test_batch/s]"
      }
     },
     "0aaf173806c048868e7b6f461005abda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0b3860d8a9384cab92f53f285c834f2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_266213c2aab54a15a05fefe2c0f891df",
       "placeholder": "​",
       "style": "IPY_MODEL_d34cfa12fc564141ac3ea11c3eaa0267",
       "value": " 1/1 [00:00&lt;00:00, 31.76test_batch/s]"
      }
     },
     "0cefd52c3b8f43ecabe4922a1c99ec89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "220ae530c2414e1c81721af8c62ae0b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "25a14ba6beb443d88b518e47a5f8d7a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "25eedd415d5f4782b9dc9da506f97cc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "266213c2aab54a15a05fefe2c0f891df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e53b55c962c44049e798bc9914cc562": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e8894b7bf9d40fe8eeff503860079d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "316efaf057db4fff926714faaed9bb45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b48a5be5a49344778f38b74e8dd76eb3",
       "placeholder": "​",
       "style": "IPY_MODEL_25eedd415d5f4782b9dc9da506f97cc6",
       "value": "Inference: 100%"
      }
     },
     "33eaee1d030549d083cf00ee0a3cfaf9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37c5f1461d0a4da190026d71e393cb7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "38028fe56ca94376a0028de81498ee2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "38bbffa5ddc145d8be99b67b541d8f71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3dd25746389b4194b8ef5778fe348587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3f7611dfa5d14772b9cb9ea71e52c4ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "40a6c6a9b8e840c2a6bf541803aec82a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4586d689b4ee414fb9ad42bbc9f9e848": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "45caab7c443d450e83dbcba9cd27dd4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7fcebefa20de486981edde53dc93e596",
        "IPY_MODEL_50cd86a0c87740dab96baaa435331ae1",
        "IPY_MODEL_f8a1c3294f5c4df89792b7d43ad35750"
       ],
       "layout": "IPY_MODEL_bd2b10a8d5544c47b009af70bb13fae3"
      }
     },
     "4e5e16a5358c466dbbaa7e2f8daef057": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "50cd86a0c87740dab96baaa435331ae1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b53dcbb8e98d41e394c636baf16faadf",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_37c5f1461d0a4da190026d71e393cb7e",
       "value": 1
      }
     },
     "538c47be78ec4250a1603939139ea218": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59250118528248ba8be2267919ebdd38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5cdd3f54a4bc4022af4804a4e3736aac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_92e6e72a32ec482a88b625c17a55a080",
        "IPY_MODEL_80fa747ccdf142d3b000f459646dac22",
        "IPY_MODEL_d32510e3408043d792d164c379357ef2"
       ],
       "layout": "IPY_MODEL_2e8894b7bf9d40fe8eeff503860079d2"
      }
     },
     "615b9d29403e43d49133fb09b16e43ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "688d32f7493a46ac9eb444a70a38b2a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9604cfc2ab624dd58d6e0b49058289c1",
        "IPY_MODEL_99604069a7f74628a2c2214f4afba15d",
        "IPY_MODEL_0a7ad8e7bc5d460b8b4714bc6fe65b26"
       ],
       "layout": "IPY_MODEL_71191373d692473ab1a5287d7e8505ca"
      }
     },
     "71191373d692473ab1a5287d7e8505ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ea9b3aacea0407daf90446ebd414850": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f3027f0f0769458480a6fc32b017bc26",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9bf40a26c6cb4b77909b9c993ddda587",
       "value": 1
      }
     },
     "7fcebefa20de486981edde53dc93e596": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8372683f35de4e81b4392ef6aa821907",
       "placeholder": "​",
       "style": "IPY_MODEL_38bbffa5ddc145d8be99b67b541d8f71",
       "value": "Inference: 100%"
      }
     },
     "80fa747ccdf142d3b000f459646dac22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0cefd52c3b8f43ecabe4922a1c99ec89",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3dd25746389b4194b8ef5778fe348587",
       "value": 1
      }
     },
     "8372683f35de4e81b4392ef6aa821907": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e01bdb1a727418d96709b9d495891b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "92e6e72a32ec482a88b625c17a55a080": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d75cc9b84ed04626afe3593a0fa45b2d",
       "placeholder": "​",
       "style": "IPY_MODEL_c440019c50b34cdd8b8c9ec3848cd300",
       "value": "Inference: 100%"
      }
     },
     "93a6141fac974eefbaa463648b76c8c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9604cfc2ab624dd58d6e0b49058289c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59250118528248ba8be2267919ebdd38",
       "placeholder": "​",
       "style": "IPY_MODEL_f0af9f5ff5bc473881d47858f3b2d6c9",
       "value": "Inference: 100%"
      }
     },
     "99604069a7f74628a2c2214f4afba15d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_93a6141fac974eefbaa463648b76c8c4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0aaf173806c048868e7b6f461005abda",
       "value": 1
      }
     },
     "9a3d40c21eb641189ab73529b2ad9220": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9bf40a26c6cb4b77909b9c993ddda587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a3624599becb4109882d3f5febb4c33c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25a14ba6beb443d88b518e47a5f8d7a4",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8e01bdb1a727418d96709b9d495891b3",
       "value": 1
      }
     },
     "ad2d9506da8041aa9f8c60f90c2a656b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5fe073d63e54979977311cca137973d",
       "placeholder": "​",
       "style": "IPY_MODEL_4e5e16a5358c466dbbaa7e2f8daef057",
       "value": ""
      }
     },
     "b48a5be5a49344778f38b74e8dd76eb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b502186055ed415eaed9b8709d281ad9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b53dcbb8e98d41e394c636baf16faadf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b672246484e54510acf8a0a4798dad15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad2d9506da8041aa9f8c60f90c2a656b",
        "IPY_MODEL_a3624599becb4109882d3f5febb4c33c",
        "IPY_MODEL_bf4dd12fbe214104b0bfe1149cb315ba"
       ],
       "layout": "IPY_MODEL_d16a0d5912e444eabd911dba738cabbb"
      }
     },
     "b8966ccbbd0240598e74f235b539ac54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_220ae530c2414e1c81721af8c62ae0b0",
       "placeholder": "​",
       "style": "IPY_MODEL_38028fe56ca94376a0028de81498ee2a",
       "value": "Inference: 100%"
      }
     },
     "bd2b10a8d5544c47b009af70bb13fae3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf4dd12fbe214104b0bfe1149cb315ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2e53b55c962c44049e798bc9914cc562",
       "placeholder": "​",
       "style": "IPY_MODEL_4586d689b4ee414fb9ad42bbc9f9e848",
       "value": " 1/? [00:00&lt;00:00, 37.51it/s]"
      }
     },
     "c440019c50b34cdd8b8c9ec3848cd300": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c549a170d5154afe81331e7d294eab61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_316efaf057db4fff926714faaed9bb45",
        "IPY_MODEL_7ea9b3aacea0407daf90446ebd414850",
        "IPY_MODEL_0b3860d8a9384cab92f53f285c834f2e"
       ],
       "layout": "IPY_MODEL_b502186055ed415eaed9b8709d281ad9"
      }
     },
     "c5fe073d63e54979977311cca137973d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c82e29dce373416dbaeb74eaacd7e847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cc80d82f550a4c5dbc53a71ae21b80d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e3b5c11e7cfb45e5849862b0b765a7a9",
       "placeholder": "​",
       "style": "IPY_MODEL_9a3d40c21eb641189ab73529b2ad9220",
       "value": " 1/1 [00:00&lt;00:00, 32.43test_batch/s]"
      }
     },
     "cedb2e4a71a145a29d04a7c0e76e78f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d16a0d5912e444eabd911dba738cabbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d32510e3408043d792d164c379357ef2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_538c47be78ec4250a1603939139ea218",
       "placeholder": "​",
       "style": "IPY_MODEL_615b9d29403e43d49133fb09b16e43ba",
       "value": " 1/1 [00:00&lt;00:00, 30.10test_batch/s]"
      }
     },
     "d34cfa12fc564141ac3ea11c3eaa0267": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d75cc9b84ed04626afe3593a0fa45b2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3227e5736b640e78b1bb72892fcc568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b8966ccbbd0240598e74f235b539ac54",
        "IPY_MODEL_f9cdc843059d4118bc84bf0a3df5a4de",
        "IPY_MODEL_cc80d82f550a4c5dbc53a71ae21b80d9"
       ],
       "layout": "IPY_MODEL_33eaee1d030549d083cf00ee0a3cfaf9"
      }
     },
     "e3b5c11e7cfb45e5849862b0b765a7a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef6ffb78fdd74758a9a8d413dab684d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f0af9f5ff5bc473881d47858f3b2d6c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f3027f0f0769458480a6fc32b017bc26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8a1c3294f5c4df89792b7d43ad35750": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cedb2e4a71a145a29d04a7c0e76e78f8",
       "placeholder": "​",
       "style": "IPY_MODEL_40a6c6a9b8e840c2a6bf541803aec82a",
       "value": " 1/1 [00:00&lt;00:00,  1.45test_batch/s]"
      }
     },
     "f9cdc843059d4118bc84bf0a3df5a4de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3f7611dfa5d14772b9cb9ea71e52c4ce",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ef6ffb78fdd74758a9a8d413dab684d2",
       "value": 1
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
